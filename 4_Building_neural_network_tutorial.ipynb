{"cells":[{"cell_type":"markdown","metadata":{"id":"RosOd1t8pdDe"},"source":["# 신경망 모델 구성하기\n","\n","* 신경망은 데이터에 대한 연산을 수행하는 계층(layer)/모듈(modeule)로 구성되어 있다.\n","* `torch.nn`: 신경망을 구성하는데 필요한 모든 구성 요소를 제공하는 네임스페이스\n","* `nn.Module`: pytorch의 모든 모듈의 상위 클래스\n","* 신경망은 다른 모듈(계층: layer)로 구성된 모듈이다. 이렇게 중첩한 구조로 복잡한 아키텍처를 쉽게 구축하고 관리할 수 있다.\n","* FashionMNIST 데이터셋의 이미지를 분류하는 신경망을 구성해보자!"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchvision\n","  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/ef/a2/f16cac894c4c71585b3411707502ed8d607945fb4a695857621565bd728d/torchvision-0.16.2-cp311-cp311-macosx_11_0_arm64.whl.metadata\n","  Downloading torchvision-0.16.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n","Requirement already satisfied: numpy in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.2)\n","Requirement already satisfied: requests in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: torch==2.1.2 in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from torchvision) (2.1.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: filelock in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (3.9.0)\n","Requirement already satisfied: typing-extensions in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (4.7.1)\n","Requirement already satisfied: sympy in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (1.11.1)\n","Requirement already satisfied: networkx in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (3.1)\n","Requirement already satisfied: jinja2 in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (3.1.2)\n","Requirement already satisfied: fsspec in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (2023.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.1.2->torchvision) (2.1.1)\n","Requirement already satisfied: mpmath>=0.19 in /Users/yoobin/anaconda3/lib/python3.11/site-packages (from sympy->torch==2.1.2->torchvision) (1.3.0)\n","Downloading torchvision-0.16.2-cp311-cp311-macosx_11_0_arm64.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: torchvision\n","Successfully installed torchvision-0.16.2\n"]}],"source":["!pip install torchvision"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10815,"status":"ok","timestamp":1703938920948,"user":{"displayName":"박유빈학부생","userId":"05269790463358912132"},"user_tz":-540},"id":"KXhJ_L4OrBgy"},"outputs":[],"source":["import os\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms"]},{"cell_type":"markdown","metadata":{"id":"ocqLMwNgqPkg"},"source":["## 1. 학습을 위한 장치 얻기\n","* 가능한 경우 GPU 또는 MPS와 같은 하드웨어 가속기에서 모델을 학습.\n","* `torch.cuda` 또는 `torch.backends.mps`가 사용 가능한지 확인해보고, 그렇지 않으면 CPU를 계속 사용"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1703938929576,"user":{"displayName":"박유빈학부생","userId":"05269790463358912132"},"user_tz":-540},"id":"4cQNwtAaqPZh","outputId":"e2ae9186-9b65-4f19-8883-6b9d6c654294"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using mps device\n"]}],"source":["device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")"]},{"cell_type":"markdown","metadata":{"id":"gqLUcMYjrNA-"},"source":["## 2. 클래스 정의하기\n","* 신경망 모델을 `nn.Module`의 하위클래스로 정의\n","* `__init__`에서 신경망 계층들을 초기화\n","* `nn.Module`을 상속받은 모든 클래스는 `forward` 메소드에 입력 데이터에 대한 연산들을 구현"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1703939872514,"user":{"displayName":"박유빈학부생","userId":"05269790463358912132"},"user_tz":-540},"id":"K4kNBShVpX5T"},"outputs":[],"source":["class NeuralNetwork(nn.Module):\n","  def __init__(self):\n","    super().__init__() # super(): 부모클래스의 임시적인 객체를 반환하여 부모클래스의 메소드를 사용할 수 있게 함\n","    self.flatten = nn.Flatten()\n","    self.linear_relu_stack = nn.Sequential(\n","        nn.Linear(28*28, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 10),\n","    )\n","\n","  def forward(self, x):\n","    x = self.flatten(x)\n","    logits = self.linear_relu_stack(x) #logit는 일반적으로 분류 모델에서 출력되는 값들을 나타내는 용어다.\n","    return logits"]},{"cell_type":"markdown","metadata":{"id":"sp4E7v2xsS5G"},"source":["* `NeuralNetwork`의 인스턴스(instance)를 생성하고 이를 `device`로 이동한 뒤, 구조(structure)를 출력"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1703939874681,"user":{"displayName":"박유빈학부생","userId":"05269790463358912132"},"user_tz":-540},"id":"nZOCuoWhsPMP","outputId":"30d48adb-d592-4107-943f-a0ebe169eec5"},"outputs":[{"name":"stdout","output_type":"stream","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}],"source":["model = NeuralNetwork().to(device)\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"Jh8qzHUWsvkd"},"source":["* 모델을 사용하기 위해 입력 데이터 전달\n","* 이는 일부 백그라운드 연산들과 함께 모델의 `forward`를 실행한다.\n","* `model.forward()`를 직접 호출하면 안됨\n","\n","* 모델에 입력을 전달하여 호출하면 2차원 텐서 반환\n","* 2차원 텐서의 dim = 0은 각 class에 대한 raw 예측값 10개, dim = 1에는 각 출력의 개별 값들이 해당\n","* 원시 예측값을 `nn.Softmax` 모듈의 인스턴스에 통과시켜 예측 확률을 얻는다."]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349,"status":"ok","timestamp":1703939877272,"user":{"displayName":"박유빈학부생","userId":"05269790463358912132"},"user_tz":-540},"id":"i8YWQmD6sgqQ","outputId":"ba6136da-246c-487a-f2b8-f9a96f445b68"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted class: tensor([9], device='cuda:0')\n"]}],"source":["X = torch.rand(1, 28, 28, device = device)\n","logits = model(X)\n","pred_probab = nn.Softmax(dim = 1)(logits)\n","y_pred = pred_probab.argmax(1)\n","print(f\"Predicted class: {y_pred}\")"]},{"cell_type":"markdown","metadata":{"id":"8s0FsJdAu9kG"},"source":["## 3. 모델 계층 (Layer)\n","* FashionMNIST 모델의 계층들을 살펴보자.\n","* 28 x 28 크기의 이미지 3개로 구성된 미니배치를 가져와 신경망을 통과할 때 어떤 일이 발생하는지 알아보자."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703940007505,"user":{"displayName":"박유빈학부생","userId":"05269790463358912132"},"user_tz":-540},"id":"xwJPbiwqtqBf","outputId":"491e8339-dd79-4aab-86f6-6546ccd7a677"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 28, 28])\n"]}],"source":["input_image = torch.rand(3, 28, 28)\n","print(input_image.size())"]},{"cell_type":"markdown","metadata":{"id":"Yhj2hW7pvTIk"},"source":["### nn.Flatten\n","* `nn.Flatten`: 계층을 초기화하여 각 28 X 28의 2D 이미지를 784 픽셀 값을 갖는 연속된 배열로 변환 (dim = 0의 미니배치 차원은 유지)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1703940468229,"user":{"displayName":"박유빈학부생","userId":"05269790463358912132"},"user_tz":-540},"id":"OLVWyHMgvSQG","outputId":"c9592b1c-fba0-483f-a346-e3f7d6d9cd62"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 784])\n"]}],"source":["flatten = nn.Flatten()\n","flat_image = flatten(input_image)\n","print(flat_image.size())"]},{"cell_type":"markdown","metadata":{"id":"VhKGDr0vvpYg"},"source":["### nn.Linear\n","* 저장된 가중치(w) & 편향(b)를 사용해 선형 변환 (linear transformation)을 적용하는 선형 계층 모듈"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703940469705,"user":{"displayName":"박유빈학부생","userId":"05269790463358912132"},"user_tz":-540},"id":"sjG1XCHRvnUc","outputId":"9fefdd54-aeea-4b3a-d484-64cbc70d5761"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 20])\n"]}],"source":["layer1 = nn.Linear(in_features = 28 * 28, out_features = 20)\n","hidden1 = layer1(flat_image)\n","print(hidden1.size())"]},{"cell_type":"markdown","metadata":{"id":"kA825mJOv_Tj"},"source":["### nn.ReLU\n","* 선형 변환 이후에 적용되어 nonlinearity 도입 & 신경망이 다양한 현상을 학습할 수 있도록 함\n","* 이 모델에서는 `nn.ReLU`를 선형 계층들 사이에 사용하지만, 모델을 만들 때는 다른 비선형성을 가진 다른 활성화를 도입할 수 있음"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703940471396,"user":{"displayName":"박유빈학부생","userId":"05269790463358912132"},"user_tz":-540},"id":"zdWWI7DXv-PD","outputId":"c1c41ad0-f7b6-446e-f9de-afe745a798b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Before ReLU: tensor([[-0.2764,  0.2738,  0.1709, -0.4190, -0.2762,  0.4262, -0.1862, -0.7226,\n","         -0.1122, -0.1257,  0.1998, -0.8544, -0.5842,  0.3435,  0.0999,  0.0392,\n","         -0.4012, -0.1264,  0.4220,  0.5195],\n","        [-0.4499,  0.3260,  0.1414, -0.5004, -0.3311,  0.2501, -0.1802, -0.5254,\n","         -0.4682, -0.5015, -0.0607, -0.4389, -0.5675,  0.5781,  0.1414,  0.0257,\n","         -0.0195, -0.0135,  0.4963,  0.3422],\n","        [-0.2331,  0.1193, -0.2282, -0.2070, -0.2654,  0.6217, -0.1826, -0.5232,\n","         -0.2234, -0.3016, -0.3195, -0.5898, -0.3203,  0.4328,  0.0721, -0.1271,\n","         -0.3701, -0.3192,  0.6468,  0.4962]], grad_fn=<AddmmBackward0>) \n","\n","\n","After ReLU: tensor([[0.0000, 0.2738, 0.1709, 0.0000, 0.0000, 0.4262, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.1998, 0.0000, 0.0000, 0.3435, 0.0999, 0.0392, 0.0000, 0.0000,\n","         0.4220, 0.5195],\n","        [0.0000, 0.3260, 0.1414, 0.0000, 0.0000, 0.2501, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.5781, 0.1414, 0.0257, 0.0000, 0.0000,\n","         0.4963, 0.3422],\n","        [0.0000, 0.1193, 0.0000, 0.0000, 0.0000, 0.6217, 0.0000, 0.0000, 0.0000,\n","         0.0000, 0.0000, 0.0000, 0.0000, 0.4328, 0.0721, 0.0000, 0.0000, 0.0000,\n","         0.6468, 0.4962]], grad_fn=<ReluBackward0>)\n"]}],"source":["print(f\"Before ReLU: {hidden1} \\n\\n\")\n","hidden1 = nn.ReLU()(hidden1)\n","print(f\"After ReLU: {hidden1}\")"]},{"cell_type":"markdown","metadata":{"id":"YDUu5aXuxIlp"},"source":["### nn.Sequential\n","* `nn.Sequential`: 순서를 갖는 모듈의 컨테이너\n","* 데이터는 정의된 순서로 모든 모듈들을 통해 전달\n","* 순차 컨테이너(sequential container)를 사용해 아래의 `seq_modules`와 같은 신경망을 빠르게 만들 수 있음\n"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703940611179,"user":{"displayName":"박유빈학부생","userId":"05269790463358912132"},"user_tz":-540},"id":"4-YTjzfLwi13"},"outputs":[],"source":["seq_modules = nn.Sequential(\n","    flatten,\n","    layer1,\n","    nn.ReLU(),\n","    nn.Linear(20, 10)\n",")\n","input_image = torch.rand(3, 28, 28)\n","logits = seq_modules(input_image)"]},{"cell_type":"markdown","metadata":{"id":"I03iEqc0xmnD"},"source":["### nn.Softmax\n","* 신경망의 마지막 선형 계층은 `nn.Softmax`모듈에 전달될 ([-infty, infty]) 범위의 raw value인 `logits`를 반환\n","* `logits`: 모델의 각 class에 대한 예측 확률을 나타내도록 [0,1] 범위로 비례하여 조정(scale)\n","* `dim` parameter: 값의 합이 1이 되는 차원을 나타냄\n"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1703940751202,"user":{"displayName":"박유빈학부생","userId":"05269790463358912132"},"user_tz":-540},"id":"2QvwJ_A9xllb"},"outputs":[],"source":["softmax = nn.Softmax(dim = 1)\n","pred_probab = softmax(logits)"]},{"cell_type":"markdown","metadata":{"id":"N93tACPcyJGD"},"source":["## 모델 매개변수\n","* 신경망 내부의 많은 계층들은 매개변수화(parameterize)된다. -> 학습 중에 최적화되는 가중치와 편향과 연관되어짐\n","* `nn.Module`을 상속하면 모델 객체 내부의 모든 필드들이 자동으로 추적(track) & 모델의 `parameters()` 및 `named_parameters()` 메소드로 모든 매개변수에 접근 가능"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"KymbZ5GMyHz_"},"outputs":[{"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 각 매개변수를 iterate하면서 매개변서의 크기와 값을 출력\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel structure : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name,param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam[:\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["# 각 매개변수를 iterate하면서 매개변서의 크기와 값을 출력\n","print(f\"Model structure : {model}\\n\\n\")\n","\n","for name,param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()} | Values: {param[:2]} \\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMoSAIX+CvKCZtAwdlOUWQy","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
